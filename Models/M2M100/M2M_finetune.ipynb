{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXdAHC3E4lWO"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.16.0\n",
        "!pip install torch\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ia_waIj4tKy"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "import urllib.request\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ],
      "metadata": {
        "id": "wZJDK1WEXIZ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq5dNt574uit"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/kt2k01/petci/main/data/json/filtered.json'\n",
        "response = urllib.request.urlopen(url)\n",
        "data = json.loads(response.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2UCA7nE4vty"
      },
      "outputs": [],
      "source": [
        "format_data = []\n",
        "i=0\n",
        "for idiom in data:\n",
        "  entry_1 = {}\n",
        "  entry_2 = {}\n",
        "\n",
        "  chinese = idiom['chinese']\n",
        "\n",
        "  if 'gold' in idiom:\n",
        "    gold = idiom['gold']\n",
        "    entry_1['id'] = i\n",
        "    i += 1\n",
        "    entry_1['prompt'] = chinese + \"</s>\"\n",
        "    entry_1['completion'] = gold + \"</s>\"\n",
        "    format_data.append(entry_1)\n",
        "\n",
        "  if idiom['human'] != []:\n",
        "    human = idiom['human'][0]\n",
        "    entry_2['id'] = i\n",
        "    i += 1\n",
        "    entry_2['prompt'] = chinese + \"</s>\"\n",
        "    entry_2['completion'] = human + \"</s>\"\n",
        "    format_data.append(entry_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EKNclFH4zkH"
      },
      "outputs": [],
      "source": [
        "    random.seed(10)\n",
        "\n",
        "    random.shuffle(format_data)\n",
        "\n",
        "    len_train = int(len(format_data) * 0.8)\n",
        "    train_data = format_data[:len_train]\n",
        "    test_data = [x for x in format_data if x not in train_data]\n",
        "    validation_data = train_data[:int(len_train * 0.2)]\n",
        "    train_data = [x for x in train_data if x not in validation_data]\n",
        "\n",
        "    src = []\n",
        "    tgt = []\n",
        "\n",
        "    for item in train_data:\n",
        "        src.append(\"translate \" + item[\"prompt\"])\n",
        "        tgt.append(item[\"completion\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the pretrained model"
      ],
      "metadata": {
        "id": "MKOy2J1rfysM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "675Khh5PG5LQ"
      },
      "outputs": [],
      "source": [
        "from transformers import M2M100Config, M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\", src_lang=\"zh\", tgt_lang=\"en\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenize data and set up training"
      ],
      "metadata": {
        "id": "m-BTDs3kglWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_texts, tgt_texts, tokenizer, max_length):\n",
        "        self.src_texts = src_texts\n",
        "        self.tgt_texts = tgt_texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        src_text = str(self.src_texts[index])\n",
        "        tgt_text = str(self.tgt_texts[index])\n",
        "\n",
        "        # Tokenize the source and target texts\n",
        "        src_tokens = self.tokenizer(src_text, padding='max_length', truncation=True, max_length=self.max_length,\n",
        "                                    return_tensors='pt')\n",
        "        tgt_tokens = self.tokenizer(tgt_text, padding='max_length', truncation=True, max_length=self.max_length,\n",
        "                                    return_tensors='pt')\n",
        "\n",
        "        # Create dictionary with source and target token IDs\n",
        "        input_ids = src_tokens['input_ids'].squeeze()\n",
        "        attention_mask = src_tokens['attention_mask'].squeeze()\n",
        "        target_ids = tgt_tokens['input_ids'].squeeze()\n",
        "\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'target_ids': target_ids}\n"
      ],
      "metadata": {
        "id": "_bbzgbGbrXZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_data = TranslationDataset(src, tgt, tokenizer, max_length=20)\n",
        "train_loader = DataLoader(translated_data, batch_size=64, shuffle=True)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)"
      ],
      "metadata": {
        "id": "8Zq8aE4Dgfqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "jMIfW-h8gt0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "    for batch in tqdm(train_loader):\n",
        "        input_ids = batch['input_ids'].to(model.device)\n",
        "        attention_mask = batch['attention_mask'].to(model.device)\n",
        "        target_ids = batch['target_ids'].to(model.device)\n",
        "\n",
        "        # Generate output sequence from model\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=target_ids[:, :-1],\n",
        "                        use_cache=False)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Compute loss and backpropagate\n",
        "        loss = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)(logits.view(-1, logits.shape[-1]),\n",
        "                                                                              target_ids[:, 1:].contiguous().view(\n",
        "                                                                                  -1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    print('Loss:', loss.item())"
      ],
      "metadata": {
        "id": "O1PdLiBkgw8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the model locally"
      ],
      "metadata": {
        "id": "7xzvhKyzg8_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('m2m100_chinese_to_english')\n",
        "tokenizer.save_pretrained('m2m100_chinese_to_english')"
      ],
      "metadata": {
        "id": "U_Vh4vkqg_Hh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}