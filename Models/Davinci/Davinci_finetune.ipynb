{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KexuanZhang/Chinese-Idioms-Translation-with-Neural-Network/blob/main/Davinci_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n",
        "!pip install openai_secret_manager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE2ihtZIEVRD",
        "outputId": "f8d2e304-9a55-4572-b4db-48e769f2af0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai_secret_manager in /usr/local/lib/python3.9/dist-packages (0.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "ymLbKcPQXBqG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO2qJf6f-jmI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/kt2k01/petci/main/data/json/filtered.json'"
      ],
      "metadata": {
        "id": "1pbQMcU0BSZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = urllib.request.urlopen(url)\n",
        "data = json.loads(response.read())"
      ],
      "metadata": {
        "id": "99r9flC9Brvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataset"
      ],
      "metadata": {
        "id": "ZmM9h7tZRyDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[-2:]"
      ],
      "metadata": {
        "id": "I4NQIdyDTGOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "\n",
        "for idiom in data:\n",
        "  entry_1 = {}\n",
        "  entry_2 = {}\n",
        "\n",
        "  chinese = idiom['chinese']\n",
        "\n",
        "  if 'gold' in idiom:\n",
        "    gold = idiom['gold']\n",
        "    entry_1['prompt'] = chinese + '->'\n",
        "    entry_1['completion'] = ' ' + gold + '\\n'\n",
        "    training_data.append(entry_1)\n",
        "\n",
        "  if idiom['human'] != []:\n",
        "    human = idiom['human'][0]\n",
        "    entry_2['prompt'] = chinese + '->'\n",
        "    entry_2['completion'] = ' ' + human + '\\n'\n",
        "    training_data.append(entry_2)"
      ],
      "metadata": {
        "id": "KYoxYfY3UETu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[:10]"
      ],
      "metadata": {
        "id": "daEfpu6fUIcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(10)\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "len_train = int(len(training_data )* 0.8)\n",
        "train_data = training_data[:len_train]\n",
        "test_data = [x for x in training_data if x not in train_data]\n",
        "validation_data = train_data[:int(len_train * 0.2)]\n",
        "train_data = [x for x in train_data if x not in validation_data]"
      ],
      "metadata": {
        "id": "V33KgkflPw64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Check formats of train and validation such that they adhere to OpenAI suggestion"
      ],
      "metadata": {
        "id": "EC7aJ0IHSEnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"train_data.jsonl\"\n",
        "\n",
        "with open(file_name, \"w\") as output_file:\n",
        "  for entry in train_data:\n",
        "    json.dump(entry, output_file)\n",
        "    output_file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "ah6CDV4Odprm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f train_data.jsonl"
      ],
      "metadata": {
        "id": "tpcy371fewzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"validation_data.jsonl\"\n",
        "\n",
        "with open(file_name, \"w\") as output_file:\n",
        "  for entry in validation_data:\n",
        "    json.dump(entry, output_file)\n",
        "    output_file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "cNMY6akuSP3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f validation_data.jsonl"
      ],
      "metadata": {
        "id": "71SIb9ddSXkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the test data doesn't need to be passed to openai since we're testing on them \n",
        "# at a different place\n",
        "\n",
        "file_name = \"test_data.jsonl\"\n",
        "\n",
        "with open(file_name, \"w\") as output_file:\n",
        "  for entry in test_data:\n",
        "    json.dump(entry, output_file)\n",
        "    output_file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "fW1p688fVMfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Establish OpenAI's API and training\n",
        "\n"
      ],
      "metadata": {
        "id": "lceH26HmW8Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "p9n8xYDOXFi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "uploading the training file"
      ],
      "metadata": {
        "id": "-4dae81Ig6Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'train_data.jsonl'\n",
        "\n",
        "upload_response_train = openai.File.create(\n",
        "  file=open(file_name, \"rb\"),\n",
        "   purpose='fine-tune'\n",
        " )\n",
        "file_id_train = upload_response_train.id\n",
        "upload_response_train"
      ],
      "metadata": {
        "id": "KtnWXFg5YRwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'validation_data.jsonl'\n",
        "\n",
        "upload_response_valid = openai.File.create(\n",
        "  file=open(file_name, \"rb\"),\n",
        "   purpose='fine-tune'\n",
        " )\n",
        "file_id_valid = upload_response_valid.id\n",
        "upload_response_valid"
      ],
      "metadata": {
        "id": "L-KNDiy9YUhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin training"
      ],
      "metadata": {
        "id": "2NU1cz-DnVeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# api_key not provided for secruity\n",
        "# openai.api_key = ..."
      ],
      "metadata": {
        "id": "q9QYrfX6X4sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_response = openai.FineTune.create(training_file=file_id_train,\n",
        "                                            validation_file=file_id_valid,\n",
        "                                            model=\"davinci\")\n",
        "fine_tune_response"
      ],
      "metadata": {
        "id": "HwYKAAcva60C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTune.retrieve(fine_tune_response.id)['status']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6kzrYSECY62q",
        "outputId": "c5e13219-7277-4439-8ffe-6e2884ea4b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pending'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "status = openai.FineTune.retrieve(fine_tune_response.id)['status']\n",
        "while status != 'succeeded':\n",
        "  print(\"current_status: \", status)\n",
        "  time.sleep(60)\n",
        "  status = openai.FineTune.retrieve(fine_tune_response.id)['status']\n",
        "\n",
        "\n",
        "print(\"current_status: \", status)"
      ],
      "metadata": {
        "id": "MYQbveq7ZCaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if openai.FineTune.retrieve(fine_tune_response.id)['status'] == 'succeeded':\n",
        "  fine_tuned_model_id = openai.FineTune.retrieve(fine_tune_response.id)['fine_tuned_model']"
      ],
      "metadata": {
        "id": "zc1d6uEnjPGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing the fine-tune model with examples"
      ],
      "metadata": {
        "id": "L9fIvV0VnHv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"心花怒放\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=fine_tuned_model_id,\n",
        "    prompt=prompt,\n",
        "    max_tokens=15\n",
        ")\n",
        "\n",
        "output_text = response.choices[0].text\n",
        "clean_output = output_text[3:].split(\"\\n\", 1)[0]\n",
        "print(clean_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pvKkTRMkTVK",
        "outputId": "b70d8aca-7bf9-439b-fdc3-4d1986e6030a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one's heart bursts into full bloom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"兴高采烈\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=fine_tuned_model_id,\n",
        "    prompt=prompt,\n",
        "    max_tokens=15\n",
        ")\n",
        "\n",
        "output_text = response.choices[0].text\n",
        "clean_output = output_text[3:].split(\"\\n\", 1)[0]\n",
        "print(clean_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3zM4aNmm1Zq",
        "outputId": "374f6061-447f-44b9-b94b-42873662ff9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in great fettle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"胸有成竹\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=fine_tuned_model_id,\n",
        "    prompt=prompt,\n",
        "    max_tokens=15\n",
        ")\n",
        "\n",
        "output_text = response.choices[0].text\n",
        "clean_output = output_text[3:].split(\"\\n\", 1)[0]\n",
        "print(clean_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB5BoWtBm836",
        "outputId": "5ccfba08-09f8-4108-d451-3c862795000c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have a well-thought-out plan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"隔墙有耳\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=fine_tuned_model_id,\n",
        "    prompt=prompt,\n",
        "    max_tokens=15\n",
        ")\n",
        "\n",
        "output_text = response.choices[0].text\n",
        "clean_output = output_text[3:].split(\"\\n\", 1)[0]\n",
        "print(clean_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSD_sbEDnvOe",
        "outputId": "046771ff-b9cd-48ca-e092-753e2a558d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the walls have ears\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"顺手牵羊\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=fine_tuned_model_id,\n",
        "    prompt=prompt,\n",
        "    max_tokens=15\n",
        ")\n",
        "\n",
        "output_text = response.choices[0].text\n",
        "clean_output = output_text[3:].split(\"\\n\", 1)[0]\n",
        "print(clean_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVVt6OWkn2li",
        "outputId": "99f8539b-d0de-4de2-be0c-b02fcae1ae08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lead the goat away from the sheepfold by the neck - filch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"一语成谶\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=fine_tuned_model_id,\n",
        "    prompt=prompt,\n",
        "    max_tokens=15\n",
        ")\n",
        "\n",
        "output_text = response.choices[0].text\n",
        "clean_output = output_text[3:].split(\"\\n\", 1)[0]\n",
        "print(clean_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut3tT7K1oM7D",
        "outputId": "77e8b761-9e78-4a53-e806-af97cd7f6c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one sentence rhyme and complete the story\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"齐心协力\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=fine_tuned_model_id,\n",
        "    prompt=prompt,\n",
        "    max_tokens=15\n",
        ")\n",
        "\n",
        "output_text = response.choices[0].text\n",
        "clean_output = output_text[3:].split(\"\\n\", 1)[0]\n",
        "print(clean_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYzlsMMfqH8T",
        "outputId": "26375012-ccff-4d0e-ecd5-0bcf384e0255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work together with one heart\n"
          ]
        }
      ]
    }
  ]
}